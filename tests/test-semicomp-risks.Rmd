---
title: "test-semicomp-risks"
author: "Jacqueline Buros"
date: "May 25, 2016"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, eval = TRUE, echo = FALSE, results = 'hide'}
root_dir <- path.expand('../')
function_dir <- root_dir
stanfile_dir <- file.path(root_dir, 'stanfiles')
library(rstan)
  rstan_options(auto_write = TRUE)
  options(mc.cores = min(parallel::detectCores(),3))
```

The goal of this document is to test the Stan file implementing semi-competing risks model in Stan. To test this code, we will compare the results to those generated by the SemiCompRisks package.

The first test data we will use is the `scrData` file provided by `SemiCompRisks`.

```{r setup-packages}
library(SemiCompRisks)
library(dplyr)
library(rstan)
data(scrData)

## sample data for this analysis
set.seed(1234)
sample_data <- scrData %>% sample_n(200)
```

The first 4 columns of this data file will form our outcome vector, where event1 is a nonterminating event (e.g. illness or rehospitalization) and event2 is a terminating event (e.g. death).  

The 5th column is a cluster ID, and the rest of the columns are covariates.

Here is the structure of the scrData: 

```{r}
str(scrData)
```

## Overview 

The `SemiCompRisks` package implements various survival & semi-competing risks models including both weibull & piecewise-exponential variations of the model.

This document will first replicate the basic Bayesian PEM (piecewise exponential model), and then estimate the PEM-MVN (version with correlated effects) since these are the models we intend to implement using Stan. 

The SemiCompRisks package supports both a Markov model and a semi-Markov model, which differ in how they treat the time to terminating event in h3. Critically, in the **Markov model**, time to death following illness = time to death (irrespective of when illness occurred). In the **Semi-Markov model**, time to death following illness = time from illness to death. 

Here, we implement h3 as a "Markov" model -- IE, the time to death is independent of the time to illness. 

## Implementing PEM model

### Background on PEM model

(content TK)

### Estimation using SemiCompRisks

Here we complete the analysis following the details given in the documentation exactly.

Data inputs (outcome & the inputs to the three hazard submodels)

```{r semi-comp-risks}
Y <- sample_data %>% dplyr::select(time1, event1, time2, event2)
## cluster <- sample_data %>% dplyr::select(cluster)
form1 <- as.formula( ~ x1 + x2 + x3)
form2 <- as.formula( ~ x1 + x2)
form3 <- as.formula( ~ x1 + x2)
lin.pred <- list(form1, form2, form3)
```

Hyperparameters (priors) for the 3 submodels 

```{r}
#####################
## Hyperparameters ##
#####################
## Subject-specific frailty variance component
## - prior parameters for 1/theta
##
theta.ab <- c(0.7, 0.7)

## PEM baseline hazard function
##
PEM.ab1 <- c(0.7, 0.7) # prior parameters for 1/sigma_1^2
PEM.ab2 <- c(0.7, 0.7) # prior parameters for 1/sigma_2^2
PEM.ab3 <- c(0.7, 0.7) # prior parameters for 1/sigma_3^2
##
PEM.alpha1 <- 10 # prior parameters for K1
PEM.alpha2 <- 10 # prior parameters for K2
PEM.alpha3 <- 10 # prior parameters for K3

## list to be passed to the BayesID function call
hyperParams <- list(theta=theta.ab,
                    WB=list(),
                    PEM=list(PEM.ab1=PEM.ab1,
                             PEM.ab2=PEM.ab2, 
                             PEM.ab3=PEM.ab3,
                             PEM.alpha1=PEM.alpha1, 
                             PEM.alpha2=PEM.alpha2, 
                             PEM.alpha3=PEM.alpha3
                             ),
                    MVN=list(),
                    DPM=list()
                    )

```

MCMC settings

```{r}

###################
## MCMC SETTINGS ##
###################
## Setting for the overall run
##
numReps <- 2000
thin <- 10
burninPerc <- 0.5

## Settings for storage
##
nGam_save <- 0          ## nGam_save, the number of Î³ to be stored
storeV <- rep(TRUE, 3)  ## whether to store posterior samples from 3 submodels

## Tuning parameters for specific updates
##
## - common to all models
mhProp_theta_var <- 0.05
mhProp_Vg_var <- c(0.05, 0.05, 0.05)

##
## - specific to the PEM specification of the baseline hazard functions
Cg <- c(0.2, 0.2, 0.2)        ## sum should be <= 0.6
delPertg <- c(0.5, 0.5, 0.5)  ## perterbation parameter 
rj.scheme <- 1 #  If rj.scheme=1, the birth update will draw the proposal time split from 1 : smax. 
               #  If rj.scheme=2, the birth update will draw the proposal time split from uniquely ordered failure times in the data.
Kg_max <- c(50, 50, 50)  ## the maximum number of splits allowed at each iteration in MHG algorithm for PEM models
sg_max <- c(max(Y$time1[Y$event1 == 1]) ## max time to event for submodel 1 (progression only)
            , max(Y$time2[Y$event1 == 0 & Y$event2 == 1]) ## max time submodel 2 (death no progression)
            , max(Y$time2[Y$event1 == 1 & Y$event2 == 1]) ## max time submodel 3 (death following progression)
            )

time_lambda1 <- seq(1, sg_max[1], 1) # timepoints at which h1 events are calculated
time_lambda2 <- seq(1, sg_max[2], 1) # timepoints at which h2 events are calculated
time_lambda3 <- seq(1, sg_max[3], 1) # timepoints at which h3 events are calculated

##
mcmc.PEM <- list(run=list(numReps=numReps
                          , thin=thin
                          , burninPerc=burninPerc
                          )
                 , storage=list(nGam_save=nGam_save
                                , storeV=storeV
                                )
                 , tuning=list(mhProp_theta_var=mhProp_theta_var
                               , mhProp_Vg_var=mhProp_Vg_var
                               , Cg=Cg
                               , delPertg=delPertg
                               , rj.scheme=rj.scheme
                               , Kg_max=Kg_max
                               , time_lambda1=time_lambda1 
                               , time_lambda2=time_lambda2
                               , time_lambda3=time_lambda3
                               )
                 )
```

Executing the model

```{r execute-pem-scr}
##
myModel <- c("Markov", "PEM")
myPath <- "Output/02-Results-PEM/"
startValues <- vector("list", 2)
startValues[[1]] <- initiate.startValues(Y, lin.pred, sample_data, model=myModel)
startValues[[2]] <- initiate.startValues(Y, lin.pred, sample_data, model=myModel, theta = 0.23)
##
fit_PEM <- BayesID(Y, lin.pred, sample_data, cluster=NULL, model=myModel, hyperParams, startValues, mcmc.PEM, path=myPath)
fit_PEM
summ.fit_PEM <- summary(fit_PEM); names(summ.fit_PEM)
summ.fit_PEM
```

Plotting at the results 

```{r plot-results}
plot(fit_PEM)
plot(fit_PEM, plot.est = "BH")
#names(fit_PEM.plot <- plot(fit_PEM, plot=FALSE))
```

### Implementing the model in Stan 

The Stan implementation of this model requires that data be provided in a "long" or denormalized format.

Data should have one observation per unique event time (failure or progression) per subject.  Each data element should have covariate values (in this case, x1, x2 & x3) provided with each observation.

Before doing any analysis, let's put the data into this structure.

```{r data-inputs}

#' @param time_precision decimal points to use when rounding time (e.g. 0 = nearest integer)
#' @returns a data frame
reformat_data <- function(data, time_precision = 2) {
  
  subjd <- data %>%
    dplyr::mutate(subject_id = row_number())
    
  ## rearrange data so that progression & failure events are on separate rows
  d <- subjd %>%
    tidyr::gather(var, val, starts_with('time'), starts_with('event')) %>%
    dplyr::mutate(event_type = gsub(var,pattern=".*(\\d)$",replacement="\\1")
                  , var = gsub(var,pattern="(.*)(\\d)$",replacement="\\1")
                  ) %>%
    tidyr::spread(var, val) %>%
    dplyr::rename(outcome = event)
  
  ## round failure times to nearest X 
  d <- 
    d %>%
    dplyr::mutate(time = round(time, time_precision)) 
  
  ## identify unique failure timepoints
  d <- d %>%
    dplyr::mutate(timepoint_id = as.integer(factor(time, ordered = TRUE)))
  
  tps <- d %>%
    dplyr::distinct(timepoint_id) %>%
    dplyr::select(timepoint_id, time) %>%
    dplyr::arrange(timepoint_id) %>%
    dplyr::rename(time_to = time) %>%
    dplyr::mutate(time_from = dplyr::lag(time_to, n = 1, order_by = timepoint_id)
                  , duration = ifelse(timepoint_id == 1, 10^(-1*time_precision), time_to - time_from)
                  )

  ## could be made *MUCH* more efficient -- don't need cum/functions
  longd <- expand.grid(list(subject_id = seq_len(nrow(data)), timepoint_id = seq_len(nrow(tps)))) %>%
    as.data.frame() %>%
    dplyr::inner_join(d %>% dplyr::rename(event_timepoint = timepoint_id), by = 'subject_id') %>%
    dplyr::mutate(progression = ifelse(event_type == 1 & outcome == 1 & timepoint_id == event_timepoint, 1, 0)
                  , failure = ifelse(event_type == 2 & outcome == 1 & timepoint_id == event_timepoint, 1, 0)
                  , censor = ifelse(event_type == 2 & outcome == 0 & timepoint_id == event_timepoint, 1, 0)
                  ) %>%
    dplyr::group_by(subject_id, timepoint_id) %>%
    dplyr::mutate(progression = max(progression)
                  , failure = max(failure)
                  , censor = max(censor)
                  ) %>%
    dplyr::group_by(subject_id) %>%
    dplyr::arrange(timepoint_id) %>%
    dplyr::mutate(post_progression = cummax(progression) - progression
                  , post_failure = cummax(failure) - failure
                  , post_censor = cummax(censor) - censor
                  ) %>%
    ungroup() %>%
    dplyr::filter(post_failure == 0 & post_censor == 0) %>%
    dplyr::select(-event_timepoint, -time, -outcome, -event_type) %>%
    unique()
  
    ## confirm no duplicates by subject/timepoint
    stopifnot(all(duplicated(cbind(longd$subject_id, longd$timepoint_id))==FALSE))
    
    ## confirm number of events the same as in original data 
    stopifnot(sum(data$event1) == sum(longd$progression))
    stopifnot(sum(data$event2) == sum(longd$failure))
  
  longd %>% inner_join(tps, by = 'timepoint_id')
}

d <- reformat_data(sampled_data, time_precision = 0.01)
str(d)
```

Next, we prepare the inputs to stan as a list of data elements

```{r stan-inputs}
standata <- list(
  ## dimensions
  N = nrow(d)
  , S = n_distinct(d$subject_id)
  , T = n_distinct(d$timepoint_id)
  , X = 3 ## number of covars
  
  ## data 
  , s_id = d$subject_id
  , t_id = d$timepoint_id
  , t_dur = d$duration
  , t_time = d$time_to
  , ev1 = d$progression
  , ev2 = d$failure
  , post_ev1 = d$post_progression
  , x = d %>% dplyr::select(x1, x2, x3)
  
  # which covariates inform which model 
  , x1 = c(1, 1, 1)  ## model1 includes all 3 covariates
  , x2 = c(1, 1, 0)  ## model2 includes first 2
  , x3 = c(1, 1, 0)  ## model3 includes first 2
)
```

Let's review the stan code for this model.

```{r print-stan-code}

```

Now, let's try running the model

```{r eval-stan}
testfit <- stan(
  file = file.path(stanfile_dir, 'semi_competing_risks_model.stan')
  , data = standata
  , chains = 1
  , iter = 10
  , control = list(adapt_delta = 0.95)
)

stanfit <- stan(
  fit = testfit
  , data = standata
  , chains = 3
  , iter = 1500
  , control = list(adapt_delta = 0.95)
  )
```


Compare results to those from the SemiCompRisks package.

```{r compare-estimates}

## estimates from h1 from semi-comp-risks
lapply()

```

```{r mvn-model-inits, eval = FALSE}

## MVN cluster-specific random effects
##
Psi_v <- diag(1, 3)
rho_v <- 100

## DPM cluster-specific random effects
##
Psi0 <- diag(1, 3)
rho0 <- 10
aTau <- 1.5
bTau <- 0.0125

```